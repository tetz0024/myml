{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter one of the following metrics key\n",
      "1:accuracy, 2:precision, 3:recall, 4:f1, 5:auc  2\n",
      "Logistic: 0.973\n",
      "LinerSVC: 0.973\n",
      "GradientBoosting: 0.947\n",
      "RandomForest: 0.946\n",
      "KNN: 0.935\n",
      "MLP: 0.935\n"
     ]
    }
   ],
   "source": [
    "# import basice apis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "\n",
    "# evaluate classifier models by input metrics \n",
    "def main():\n",
    "    dataset = load_dataset\n",
    "    X = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    y = pd.DataFrame(dataset.target, columns=['y'])\n",
    "\n",
    "    # cross-validation by holdout\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.20, random_state=1)\n",
    "\n",
    "    # set pipelines for algorithms\n",
    "    \n",
    "    pipe_knn = Pipeline([('scl',StandardScaler()), ('est',KNeighborsClassifier())])\n",
    "    \n",
    "    pipe_logistic = Pipeline([('scl', StandardScaler()), ('est',LogisticRegression(random_state=1))])\n",
    "    \n",
    "    pipe_rf = Pipeline([('scl',StandardScaler()),('est',RandomForestClassifier(random_state=1))])\n",
    "    \n",
    "    pipe_gb = Pipeline([('scl',StandardScaler()),('est',GradientBoostingClassifier(random_state=1))])\n",
    "    \n",
    "    pipe_mlp = Pipeline([('scl',StandardScaler()),('est',MLPClassifier(max_iter=1000,hidden_layer_sizes=(5,3),random_state=1))])\n",
    "    \n",
    "    pipe_svc = Pipeline([('scl',StandardScaler()),('est',LinearSVC(random_state=1))])\n",
    "\n",
    "    # evaluate following metrics\n",
    "    # - 1 : accuracy  : 正解率\n",
    "    # - 2 : precision : 適合率\n",
    "    # - 3 : recall    : 再現率\n",
    "    # - 4 : f1        : F1スコア\n",
    "    # - 5 : auc       : AUC\n",
    "    print('Enter one of the following metrics key')\n",
    "    input_metrics = input('1:accuracy, 2:precision, 3:recall, 4:f1, 5:auc  ') \n",
    "\n",
    "    pipe_names = ['KNN','Logistic','RandomForest','GradientBoosting','MLP','LinerSVC']\n",
    "    pipe_lines = [pipe_knn, pipe_logistic, pipe_rf, pipe_gb, pipe_mlp, pipe_svc]\n",
    "    pipe_scores = {}\n",
    "\n",
    "    # exec evaluate\n",
    "    for (i,pipe) in enumerate(pipe_lines):\n",
    "        pipe.fit(X_train, y_train.as_matrix().ravel())\n",
    "        # accuracy \n",
    "        if input_metrics == '1': \n",
    "            pipe_scores[pipe_names[i]] = accuracy_score(y_test, pipe.predict(X_test))\n",
    "        # precision \n",
    "        elif input_metrics == '2':\n",
    "            pipe_scores[pipe_names[i]] = precision_score(y_test, pipe.predict(X_test))\n",
    "        # recall\n",
    "        elif input_metrics == '3':\n",
    "            pipe_scores[pipe_names[i]] = recall_score(y_test, pipe.predict(X_test))\n",
    "        # f1     \n",
    "        elif input_metrics == '4':\n",
    "            pipe_scores[pipe_names[i]] = f1_score(y_test, pipe.predict(X_test))\n",
    "        # auc    \n",
    "        elif input_metrics == '5':\n",
    "            pipe_scores[pipe_names[i]] = roc_auc_score(y_test, pipe.predict(X_test))\n",
    "\n",
    "        else:\n",
    "            print('invalid input_metrics')\n",
    "            break\n",
    "\n",
    "    # print scores sorted descend\n",
    "    for pipe, score in sorted(pipe_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "        print('%s: %.3f' %(pipe, score))\n",
    "\n",
    "    # output best model\n",
    "    best_scores = [kv for kv in pipe_scores.items() if kv[1] == max(pipe_scores.values())]\n",
    "    # dump pkl\n",
    "    with open( 'best_models.pickle', mode='wb') as f:\n",
    "        pickle.dump(best_scores, f)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # set parameter\n",
    "  # import Sample Data to learn models\n",
    "  load_dataset = datasets.load_breast_cancer()\n",
    "\n",
    "  # main proc\n",
    "  main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
